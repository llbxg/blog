+++
title = "OpenSeeFaceとGodot4を繋ぐ"
date = "2023-06-03"
description = "OpenSeeFaceで顔のランドマークを検出して、結果をソケット通信(UDP)で受け取ったときのメモです。"
[taxonomies]
tags = ["Godot4", "OpenSeeFace", "Python"]
+++

OpenSeeFace[^1]で顔のランドマークを検出して、結果をソケット通信(UDP)で受け取ったときのメモです。

c#で受け取る例を示します。ついでに、pythonをGodotから実行する方法も載せておきます。

[TOC]

## 環境

Godot: `v4.0.2.stable.official`

Python: `3.9.9`

OpenSeeFace: `9e07f6e1993022e7679f2e5ee3daec0ff617fac1`

## OpenSeeFaceとは

OpenSeeFaceは、MobileNetV3に基づいた顔のランドマーク検出モデルを実装したトラッキングライブラリです。
顔の特徴点(ランドマーク)を検出し、それを基に顔の動きを追跡することができます。

Webカメラ入力またはビデオファイルからの顔のトラッキングを行い、そのトラッキングデータを**UDP経由で送信**します。

この送信されたデータは3Dモデル、またはLive2Dモデルのアニメーションで利用できます。

このライブラリでは、複数のモデルを提供しており、ユーザーの環境に合わせて変更できます。

## データの送信側

OpenSeeFaceでは`facetracker.py`[^2]を実行して起動します。

```bash
$ python facetracker.py -P 1 --log-data output.log
```

`facetracker.py`にてsendtoによりトラッキングデータが送信されています。

```python
sock.sendto(packet,  (target_ip,  target_port))
```

デフォルトではipがlocalhost(127.0.0.1)、portは11573です。実行時の引数として与えることもできます。

`packet`は`bytearray()`によって作成され、`packet.extend(bytearray(struct.pack("d",  now)))`のようにデータを追加しています。

何のデータが出力されているかはlogファイルを確認するのが良いでしょう。少し多すぎるのでここでの記載は省略しますが、各フィードのメモをおまけとして追加しておきます。
<!-- [特徴データのメモ](#_4) -->

## Godotで受け取る

c#では、UDPのサーバーとして`UDPServer`[^3]を使用できます。

公式ドキュメントを参考に、以下のようにOpenSeeFaceからデータを取得することができます。

```c#
extends Node

var server := UDPServer.new()

func _ready():
	server.listen(11573)


func _process(delta):
	server.poll()
	if server.is_connection_available():
		var peer = server.take_connection()
		var packet = peer.get_packet()
```

取得したデータ(`packet`)はbyte形式ですので、こちらを変換する必要があります。

そこで一旦、変換用の関数を定義しておきます。(もしかするともう少しいい変換方法があるかもです。)

```c#
func bytes_to_double(bytes):
	var double: float = 0.0
	if bytes.size() == 8:
		var f64 = bytes.decode_double(0)
		double = float(f64)
	return double


func bytes_to_int(bytes):
	var integer: int = 0
	if bytes.size() == 4:
		var i32 = bytes.decode_u32(0)
		integer = int(i32)
	return integer


func bytes_to_float(bytes):
	var float_number: float = 0.0
	if bytes.size() == 4:
		var f32 = bytes.decode_float(0)
		float_number = float(f32)
	return float_number
```

あとはいい感じに受け取ったデータを区切って、辞書型に保存する関数を定義します。

これで`data`を取得することで特徴データを使用できます。

```c#

func parse_packet(packet):
	var data = {}
	var index = 0

	var timestamp_bytes = packet.slice(index, index + 8)
	var timestamp = bytes_to_double(timestamp_bytes)
	data["timestamp"] = timestamp
	index += 8

	var face_id_bytes = packet.slice(index, index + 4)
	var face_id = bytes_to_int(face_id_bytes)
	data["face_id"] = face_id
	index += 4

	var width_bytes = packet.slice(index, index + 4)
	var width = bytes_to_float(width_bytes)
	data["width"] = width
	index += 4

	var height_bytes = packet.slice(index, index + 4)
	var height = bytes_to_float(height_bytes)
	data["height"] = height
	index += 4

	data["eye_blink"] = []
	data["eye_blink"].append(bytes_to_float(packet.slice(index, index + 4)))
	index += 4
	data["eye_blink"].append(bytes_to_float(packet.slice(index, index + 4)))
	index += 4

	var success_bytes = packet.slice(index, index + 1)
	var success = bytes_to_int(success_bytes)
	data["success"] = success
	index += 1

	var pnp_error_bytes = packet.slice(index, index + 4)
	var pnp_error = bytes_to_float(pnp_error_bytes)
	data["pnp_error"] = pnp_error
	index += 4

	var quaternions = []
	for i in range(4):
		quaternions.append(bytes_to_float(packet.slice(index + i * 4, index + (i + 1) * 4)))
		data["quaternion"] = quaternions

	var eulers = []
	for i in range(3):
		eulers.append(bytes_to_float(packet.slice(index + i * 4, index + (i + 1) * 4)))
	data["euler"] = eulers
	index += 12

	var translations = []
	for i in range(3):
		translations.append(bytes_to_float(packet.slice(index + i * 4, index + (i + 1) * 4)))
	data["translation"] = translations
	index += 12

	index += 66 * 3 * 4  # Landmark

	index += 66 * 3 * 4  # Point3D

	index += 18 * 4  # ???

	# Feature list
	var features = [
		"eye_l", "eye_r", "eyebrow_steepness_l", "eyebrow_quirk_l",
		"eyebrow_steepness_r", "eyebrow_quirk_r", "eyebrow_updown_l",
		"eyebrow_updown_r", "mouth_corner_updown_l", "mouth_corner_inout_l",
		"mouth_corner_updown_r", "mouth_corner_inout_r", "mouth_open", "mouth_wide"
	]

	data["features"] = {}
	for i in range(14):
		data["features"][features[i]] = bytes_to_float(packet.slice(index, index + 4))
		index += 4

	return data
```




## pythonをGodotから呼ぶ

いちいち、`facetracker.py`を起動して、Godotでパペットを起動してとするのは非常に手間がかかります。

そこでmainのスクリプトなどで最初に実行してしまうことにします。

`OS.execute`[^4]を使うと、OpenSeeFaceが停止するまで、それ以降の処理が実行されません。

そのため、`OS.create_process`[^5]を使用して、新しいプロセスを作成し、実行します。

```c#
const python_cmd = "<path to python>"

func run_py():
	var output = []
	var args = [
		"OpenSeeFace/facetracker.py", 
		"--visualize", "3", 
		"--pnp-points", "1", 
		"--max-threads", "4", 
		"-c", "0", 
		"-P", "1", 
		"-F", "60"]
	var pid = OS.create_process(python_cmd, args)
	
	return pid
```

これで実行はされます。しかし、これだとGodotが終了してもプロセスが実行され続けてしまいます。

`_notification`関数内で`NOTIFICATION_WM_CLOSE_REQUEST`を使用してウィンドウが閉じられたことを検出します。。

あとは、実行時に取得したpidを使って`OS.kill`によってkillします。

```c#
func _notification(what):
	if what == NOTIFICATION_WM_CLOSE_REQUEST:
		get_tree().set_auto_accept_quit(false)
		OS.kill(pid)
		get_tree().quit()
```

## おまけ: パペット風の出力例

上記スクリプトを使って、ためしにパペットを作ってみました。

取得した特徴データのうち目の開閉と口の開閉、加えて顔の傾きを使用して出力しています。

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">顔トラッキング60fpsで動作確認した👀👄<a href="https://twitter.com/hashtag/GODOT4?src=hash&amp;ref_src=twsrc%5Etfw">#GODOT4</a> <a href="https://twitter.com/hashtag/OpenSeeFace?src=hash&amp;ref_src=twsrc%5Etfw">#OpenSeeFace</a> <a href="https://t.co/C7iFZoYZJH">pic.twitter.com/C7iFZoYZJH</a></p>&mdash; kosh (@llbxg) <a href="https://twitter.com/llbxg/status/1655534078911991808?ref_src=twsrc%5Etfw">May 8, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## おまけ: 特徴データのメモ

各フィードのメモです。

* Frame, Time: 映像フレームのIDとそのタイムスタンプ。
* Width, Height: 映像の幅と高さ。
* FPS: 映像のフレームレート（フレーム・パー・セカンド）。
* Face, FaceID: 顔の検出とその識別子。
* RightOpen, LeftOpen: 右目と左目が開いているかどうかの指標。
* AverageConfidence: 検出された顔の信頼度の平均。
* Success3D, PnPError: 3D顔再構成の成功とそのエラー。
* RotationQuat.X, Y, Z, W: 顔の回転を表すクォータニオン。
* Euler.X, Y, Z: オイラー角による顔の回転。
* RVec.X, Y, Z, TVec.X, Y, Z: 顔の位置と姿勢を表すロドリゲスベクトルと平行移動ベクトル。
* Landmark[i].X, Y, Confidence: i番目の顔のランドマーク（特徴点）の位置とその信頼度。
* Point3D[i].X, Y, Z: i番目の3Dランドマークの位置。
* eye_l, eye_r: 左目と右目の開き具合。
* eyebrow_steepness_l, eyebrow_updown_l, eyebrow_quirk_l, eyebrow_steepness_r, eyebrow_updown_r, eyebrow_quirk_r: 左右の眉の特性（傾き、上下動、特異な動き）。
* mouth_corner_updown_l, mouth_corner_inout_l, mouth_corner_updown_r, mouth_corner_inout_r: 口角の上下動と内外動。
* mouth_open, mouth_wide: 口の開き具合と幅。

## 参考文献

[^1]: [emilianavt/OpenSeeFace - GitHub](https://github.com/emilianavt/OpenSeeFace)

[^2]: [OpenSeeFace - GitHub - facetracker.py](https://github.com/emilianavt/OpenSeeFace/blob/master/facetracker.py)

[^3]: [class_udpserver #udpserver - docs.godotengine.org](https://docs.godotengine.org/en/stable/classes/class_udpserver.html#udpserver)

[^4]: [class_os.html #class-os-method-execute - docs.godotengine.org](https://docs.godotengine.org/en/stable/classes/class_os.html#class-os-method-execute)

[^5]: [class_os.html #class-os-method-create-process - docs.godotengine.org](https://docs.godotengine.org/en/stable/classes/class_os.html#class-os-method-create-process)

[^6]: [class_os.html #class-os-method-kill - docs.godotengine.org](https://docs.godotengine.org/en/stable/classes/class_os.html#class-os-method-kill)